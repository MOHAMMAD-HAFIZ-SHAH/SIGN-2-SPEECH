{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70dd2112",
   "metadata": {},
   "source": [
    "# CNN Model Performance Visualization\n",
    "## ASL Sign Language Recognition System\n",
    "\n",
    "This notebook generates comprehensive visualizations including:\n",
    "- Dataset distribution\n",
    "- Confusion matrices\n",
    "- Per-class metrics (Precision, Recall, F1-Score)\n",
    "- Prediction confidence analysis\n",
    "- Sample predictions\n",
    "- Model architecture summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216121c6",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70247771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from tensorflow.keras.models import load_model\n",
    "import json\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better-looking plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# For inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef824921",
   "metadata": {},
   "source": [
    "## 2. Configuration & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f047af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "IMG_SIZE = 64  # Model uses 64x64 images\n",
    "MIN_THRESHOLD_VALUE = 70\n",
    "DATASET_PATH = 'dataset'  # Dataset in model-training directory\n",
    "MODEL_PATH = '../frontend/public/models/best_model.h5'  # Using existing trained model\n",
    "METADATA_PATH = '../frontend/public/models/model_metadata.json'\n",
    "OUTPUT_DIR = 'visualizations'\n",
    "MAX_SAMPLES_PER_CLASS = 100  # Limit samples for faster processing\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"ðŸ“ Output directory: {OUTPUT_DIR}/\")\n",
    "print(f\"ðŸ–¼ï¸  Image size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"ðŸ“Š Max samples per class: {MAX_SAMPLES_PER_CLASS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973f015c",
   "metadata": {},
   "source": [
    "## 3. Image Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e152175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_asl_style(img, img_size=IMG_SIZE, min_value=MIN_THRESHOLD_VALUE):\n",
    "    \"\"\"\n",
    "    Preprocessing pipeline from training:\n",
    "    1. Convert to grayscale\n",
    "    2. Gaussian blur\n",
    "    3. Adaptive thresholding\n",
    "    4. Otsu's method\n",
    "    5. Resize to target size\n",
    "    \"\"\"\n",
    "    try:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray, (5, 5), 2)\n",
    "        th3 = cv2.adaptiveThreshold(\n",
    "            blur, 255, \n",
    "            cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "            cv2.THRESH_BINARY_INV, 11, 2\n",
    "        )\n",
    "        ret, res = cv2.threshold(\n",
    "            th3, min_value, 255, \n",
    "            cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU\n",
    "        )\n",
    "        resized = cv2.resize(res, (img_size, img_size))\n",
    "        return resized\n",
    "    except Exception as e:\n",
    "        print(f'Exception in preprocessing: {e}')\n",
    "        return None\n",
    "\n",
    "print(\"âœ… Preprocessing function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce53feb1",
   "metadata": {},
   "source": [
    "## 4. Load Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387d218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(data_path, img_size=IMG_SIZE, max_per_class=MAX_SAMPLES_PER_CLASS):\n",
    "    \"\"\"Load test dataset with sampling for faster processing\"\"\"\n",
    "    print(f\"Loading test dataset (max {max_per_class} samples per class)...\\n\")\n",
    "    \n",
    "    categories = sorted([d for d in os.listdir(data_path) \n",
    "                        if os.path.isdir(os.path.join(data_path, d)) and len(d) == 1])\n",
    "    \n",
    "    label_dict = {category: idx for idx, category in enumerate(categories)}\n",
    "    \n",
    "    data = []\n",
    "    target = []\n",
    "    file_paths = []\n",
    "    \n",
    "    for category in categories:\n",
    "        cat_path = os.path.join(data_path, category)\n",
    "        img_names = [f for f in os.listdir(cat_path) \n",
    "                     if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        \n",
    "        # Sample images if there are too many\n",
    "        if len(img_names) > max_per_class:\n",
    "            img_names = np.random.choice(img_names, max_per_class, replace=False)\n",
    "        \n",
    "        print(f\"  {category}: {len(img_names)} images\", end='  ')\n",
    "        if (categories.index(category) + 1) % 5 == 0:\n",
    "            print()\n",
    "        \n",
    "        for img_name in img_names:\n",
    "            img_path = os.path.join(cat_path, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            \n",
    "            if img is None:\n",
    "                continue\n",
    "            \n",
    "            processed = preprocess_image_asl_style(img, img_size)\n",
    "            \n",
    "            if processed is not None:\n",
    "                data.append(processed)\n",
    "                target.append(label_dict[category])\n",
    "                file_paths.append(img_path)\n",
    "    \n",
    "    data = np.array(data) / 255.0\n",
    "    data = np.reshape(data, (data.shape[0], img_size, img_size, 1))\n",
    "    target = np.array(target)\n",
    "    \n",
    "    print(f\"\\n\\nâœ… Total loaded: {len(data)} test images from {len(categories)} classes\")\n",
    "    return data, target, categories, label_dict, file_paths\n",
    "\n",
    "# Load the data\n",
    "X_test, y_test, categories, label_dict, file_paths = load_test_data(DATASET_PATH)\n",
    "print(f\"\\nðŸ“Š Data shape: {X_test.shape}\")\n",
    "print(f\"ðŸ·ï¸  Categories: {categories}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37492591",
   "metadata": {},
   "source": [
    "## 5. Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63171f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loading model from {MODEL_PATH}...\")\n",
    "\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print(f\"âŒ Error: Model not found at {MODEL_PATH}\")\n",
    "    print(\"Please train the model first using train_asl_model.py\")\n",
    "else:\n",
    "    model = load_model(MODEL_PATH)\n",
    "    print(\"âœ… Model loaded successfully!\\n\")\n",
    "    \n",
    "    # Display model summary\n",
    "    print(\"ðŸ“‹ Model Summary:\")\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a334ca",
   "metadata": {},
   "source": [
    "## 6. Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccd41d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ”® Generating predictions...\\n\")\n",
    "predictions = model.predict(X_test, verbose=1)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "overall_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nðŸŽ¯ Overall Accuracy: {overall_accuracy:.4f} ({overall_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fed4bbb",
   "metadata": {},
   "source": [
    "## 7. Visualization 1: Dataset Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63b9780",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“Š Creating dataset distribution plot...\\n\")\n",
    "\n",
    "class_counts = Counter(y_test)\n",
    "labels = [categories[i] for i in sorted(class_counts.keys())]\n",
    "counts = [class_counts[i] for i in sorted(class_counts.keys())]\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "bars = plt.bar(labels, counts, color=plt.cm.viridis(np.linspace(0, 1, len(labels))))\n",
    "plt.xlabel('Sign Language Letter', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Number of Samples', fontsize=12, fontweight='bold')\n",
    "plt.title('Dataset Distribution - Samples per Class', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=0, fontsize=10)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(height)}',\n",
    "            ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, '1_dataset_distribution.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"âœ… Saved: 1_dataset_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6359d93f",
   "metadata": {},
   "source": [
    "## 8. Visualization 2: Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006327b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ”² Creating confusion matrix...\\n\")\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Plot both raw and normalized\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 9))\n",
    "\n",
    "# Raw confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=categories, yticklabels=categories,\n",
    "            cbar_kws={'label': 'Count'}, ax=axes[0])\n",
    "axes[0].set_title('Confusion Matrix (Raw Counts)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Normalized confusion matrix\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='RdYlGn', \n",
    "            xticklabels=categories, yticklabels=categories,\n",
    "            cbar_kws={'label': 'Proportion'}, ax=axes[1])\n",
    "axes[1].set_title('Confusion Matrix (Normalized)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, '2_confusion_matrix.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"âœ… Saved: 2_confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807d3e8b",
   "metadata": {},
   "source": [
    "## 9. Visualization 3: Per-Class Metrics (Precision, Recall, F1-Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800231ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“Š Creating per-class metrics plot...\\n\")\n",
    "\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    y_test, y_pred, labels=range(len(categories)), zero_division=0\n",
    ")\n",
    "\n",
    "x = np.arange(len(categories))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "bars1 = ax.bar(x - width, precision, width, label='Precision', alpha=0.8)\n",
    "bars2 = ax.bar(x, recall, width, label='Recall', alpha=0.8)\n",
    "bars3 = ax.bar(x + width, f1, width, label='F1-Score', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Sign Language Letter', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Per-Class Performance Metrics', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(categories)\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_ylim([0, 1.1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, '3_per_class_metrics.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"âœ… Saved: 3_per_class_metrics.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928ba221",
   "metadata": {},
   "source": [
    "## 10. Visualization 4: Per-Class Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73860e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“Š Creating per-class accuracy plot...\\n\")\n",
    "\n",
    "accuracies = []\n",
    "for i, category in enumerate(categories):\n",
    "    mask = y_test == i\n",
    "    if mask.sum() > 0:\n",
    "        acc = (y_pred[mask] == i).sum() / mask.sum()\n",
    "        accuracies.append(acc * 100)\n",
    "    else:\n",
    "        accuracies.append(0)\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "colors = ['green' if acc >= 90 else 'orange' if acc >= 70 else 'red' \n",
    "          for acc in accuracies]\n",
    "bars = plt.bar(categories, accuracies, color=colors, alpha=0.7, edgecolor='black')\n",
    "\n",
    "plt.axhline(y=90, color='green', linestyle='--', alpha=0.5, label='90% threshold')\n",
    "plt.axhline(y=70, color='orange', linestyle='--', alpha=0.5, label='70% threshold')\n",
    "\n",
    "plt.xlabel('Sign Language Letter', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "plt.title('Per-Class Accuracy', fontsize=14, fontweight='bold')\n",
    "plt.ylim([0, 105])\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.1f}%',\n",
    "            ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, '4_per_class_accuracy.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"âœ… Saved: 4_per_class_accuracy.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b2840e",
   "metadata": {},
   "source": [
    "## 11. Visualization 5: Prediction Confidence Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275101b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“Š Creating prediction confidence plot...\\n\")\n",
    "\n",
    "max_confidences = np.max(predictions, axis=1)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "correct_mask = predicted_classes == y_test\n",
    "correct_confidences = max_confidences[correct_mask]\n",
    "incorrect_confidences = max_confidences[~correct_mask]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(correct_confidences, bins=50, alpha=0.7, label='Correct', color='green', edgecolor='black')\n",
    "axes[0].hist(incorrect_confidences, bins=50, alpha=0.7, label='Incorrect', color='red', edgecolor='black')\n",
    "axes[0].set_xlabel('Confidence Score', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Prediction Confidence Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "data_to_plot = [correct_confidences, incorrect_confidences]\n",
    "axes[1].boxplot(data_to_plot, tick_labels=['Correct', 'Incorrect'], patch_artist=True,\n",
    "                boxprops=dict(facecolor='lightblue', alpha=0.7))\n",
    "axes[1].set_ylabel('Confidence Score', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Confidence Score Comparison', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, '5_prediction_confidence.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"âœ… Saved: 5_prediction_confidence.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a56155b",
   "metadata": {},
   "source": [
    "## 12. Visualization 6: Most Confused Letter Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdd3435",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ”€ Creating most confused pairs plot...\\n\")\n",
    "\n",
    "confusion_pairs = []\n",
    "for i in range(len(categories)):\n",
    "    for j in range(len(categories)):\n",
    "        if i != j and cm[i, j] > 0:\n",
    "            confusion_pairs.append({\n",
    "                'true': categories[i],\n",
    "                'predicted': categories[j],\n",
    "                'count': cm[i, j],\n",
    "                'pair': f\"{categories[i]}â†’{categories[j]}\"\n",
    "            })\n",
    "\n",
    "confusion_pairs = sorted(confusion_pairs, key=lambda x: x['count'], reverse=True)[:10]\n",
    "\n",
    "if confusion_pairs:\n",
    "    pairs = [item['pair'] for item in confusion_pairs]\n",
    "    counts = [item['count'] for item in confusion_pairs]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    colors = plt.cm.Reds(np.linspace(0.4, 0.9, len(pairs)))\n",
    "    bars = plt.barh(pairs, counts, color=colors, edgecolor='black')\n",
    "    plt.xlabel('Number of Misclassifications', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('True â†’ Predicted', fontsize=12, fontweight='bold')\n",
    "    plt.title(f'Top 10 Most Confused Letter Pairs', fontsize=14, fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        plt.text(width, bar.get_y() + bar.get_height()/2.,\n",
    "                f'{int(width)}',\n",
    "                ha='left', va='center', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, '6_most_confused_pairs.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"âœ… Saved: 6_most_confused_pairs.png\")\n",
    "else:\n",
    "    print(\"âš ï¸  No confused pairs found (perfect classification!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c127d193",
   "metadata": {},
   "source": [
    "## 13. Visualization 7: Sample Predictions with Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b84a858",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ–¼ï¸  Creating sample predictions visualization...\\n\")\n",
    "\n",
    "num_samples = 16\n",
    "indices = np.random.choice(len(X_test), size=min(num_samples, len(X_test)), replace=False)\n",
    "\n",
    "sample_predictions = model.predict(X_test[indices], verbose=0)\n",
    "predicted_classes = np.argmax(sample_predictions, axis=1)\n",
    "confidences = np.max(sample_predictions, axis=1)\n",
    "\n",
    "rows = 4\n",
    "cols = 4\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(12, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, (i, ax) in enumerate(zip(indices, axes)):\n",
    "    img = X_test[i].squeeze()\n",
    "    true_label = categories[y_test[i]]\n",
    "    pred_label = categories[predicted_classes[idx]]\n",
    "    confidence = confidences[idx]\n",
    "    \n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    color = 'green' if true_label == pred_label else 'red'\n",
    "    title = f'True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.2f}'\n",
    "    ax.set_title(title, fontsize=9, color=color, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Sample Predictions (Green=Correct, Red=Incorrect)', \n",
    "             fontsize=14, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, '7_sample_predictions.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"âœ… Saved: 7_sample_predictions.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b8f015",
   "metadata": {},
   "source": [
    "## 14. Visualization 8: Model Architecture Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e893b2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ—ï¸  Creating model architecture summary...\\n\")\n",
    "\n",
    "layer_info = []\n",
    "for layer in model.layers:\n",
    "    try:\n",
    "        output_shape = str(layer.output_shape) if hasattr(layer, 'output_shape') else 'N/A'\n",
    "    except:\n",
    "        output_shape = 'N/A'\n",
    "    \n",
    "    layer_info.append({\n",
    "        'name': layer.name,\n",
    "        'type': layer.__class__.__name__,\n",
    "        'output_shape': output_shape,\n",
    "        'params': layer.count_params()\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(layer_info)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "table = ax.table(cellText=df.values, colLabels=df.columns,\n",
    "                 cellLoc='left', loc='center',\n",
    "                 colWidths=[0.25, 0.2, 0.3, 0.15])\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(9)\n",
    "table.scale(1, 2)\n",
    "\n",
    "# Style header\n",
    "for i in range(len(df.columns)):\n",
    "    table[(0, i)].set_facecolor('#4CAF50')\n",
    "    table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "\n",
    "# Alternate row colors\n",
    "for i in range(1, len(df) + 1):\n",
    "    for j in range(len(df.columns)):\n",
    "        if i % 2 == 0:\n",
    "            table[(i, j)].set_facecolor('#f0f0f0')\n",
    "\n",
    "total_params = model.count_params()\n",
    "plt.title(f'CNN Model Architecture Summary\\nTotal Parameters: {total_params:,}', \n",
    "          fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, '8_model_architecture.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"âœ… Saved: 8_model_architecture.png\")\n",
    "\n",
    "# Also display as DataFrame\n",
    "print(\"\\nðŸ“‹ Model Architecture Details:\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768bff67",
   "metadata": {},
   "source": [
    "## 15. Generate Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6bc750",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“„ Generating classification report...\\n\")\n",
    "\n",
    "report = classification_report(y_test, y_pred, target_names=categories, digits=3, zero_division=0)\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR, '9_classification_report.txt'), 'w') as f:\n",
    "    f.write(\"=\" * 60 + \"\\n\")\n",
    "    f.write(\"DETAILED CLASSIFICATION REPORT\\n\")\n",
    "    f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "    f.write(report)\n",
    "    f.write(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
    "    f.write(f\"Overall Accuracy: {accuracy_score(y_test, y_pred):.4f}\\n\")\n",
    "    f.write(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "print(\"âœ… Saved: 9_classification_report.txt\\n\")\n",
    "print(report)\n",
    "print(f\"\\nðŸŽ¯ Overall Accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf27d08e",
   "metadata": {},
   "source": [
    "## 16. Visualization 10: Summary Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906d99ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“Š Creating summary dashboard...\\n\")\n",
    "\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Title\n",
    "fig.suptitle('CNN Model Performance Dashboard', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Overall accuracy (large display)\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "ax1.text(0.5, 0.5, f'{overall_accuracy*100:.2f}%', \n",
    "         ha='center', va='center', fontsize=60, fontweight='bold',\n",
    "         color='green' if overall_accuracy >= 0.9 else 'orange' if overall_accuracy >= 0.7 else 'red')\n",
    "ax1.text(0.5, 0.15, 'Overall Accuracy', \n",
    "         ha='center', va='center', fontsize=14, fontweight='bold')\n",
    "ax1.axis('off')\n",
    "\n",
    "# Key statistics\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "ax2.text(0.5, 0.7, str(len(categories)), \n",
    "         ha='center', va='center', fontsize=36, fontweight='bold', color='blue')\n",
    "ax2.text(0.5, 0.3, 'Classes', \n",
    "         ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "ax2.axis('off')\n",
    "\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "ax3.text(0.5, 0.7, 'CNN', \n",
    "         ha='center', va='center', fontsize=36, fontweight='bold', color='purple')\n",
    "ax3.text(0.5, 0.3, 'Model Type', \n",
    "         ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "ax3.axis('off')\n",
    "\n",
    "ax4 = fig.add_subplot(gs[1, 2])\n",
    "ax4.text(0.5, 0.7, f'{IMG_SIZE}x{IMG_SIZE}', \n",
    "         ha='center', va='center', fontsize=36, fontweight='bold', color='teal')\n",
    "ax4.text(0.5, 0.3, 'Input Size', \n",
    "         ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "ax4.axis('off')\n",
    "\n",
    "# Info text\n",
    "ax5 = fig.add_subplot(gs[2, :])\n",
    "info_text = (\n",
    "    \"ASL Sign Language Recognition System\\n\"\n",
    "    \"Using Convolutional Neural Networks for A-Z Classification\\n\"\n",
    "    f\"Dataset: {len(categories)} letter categories | \"\n",
    "    f\"Preprocessing: Grayscale â†’ Blur â†’ Adaptive Threshold â†’ Otsu â†’ Resize\"\n",
    ")\n",
    "ax5.text(0.5, 0.5, info_text, \n",
    "         ha='center', va='center', fontsize=10, \n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "ax5.axis('off')\n",
    "\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, '10_summary_dashboard.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"âœ… Saved: 10_summary_dashboard.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856fac4f",
   "metadata": {},
   "source": [
    "## 17. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cd1061",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ“Š FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Overall Accuracy: {overall_accuracy:.4f} ({overall_accuracy*100:.2f}%)\")\n",
    "print(f\"ðŸ“ Total Test Samples: {len(X_test)}\")\n",
    "print(f\"ðŸ·ï¸  Number of Classes: {len(categories)}\")\n",
    "print(f\"âœ… Correct Predictions: {(y_pred == y_test).sum()}\")\n",
    "print(f\"âŒ Incorrect Predictions: {(y_pred != y_test).sum()}\")\n",
    "\n",
    "# Best performing classes\n",
    "best_classes = [(categories[i], acc) for i, acc in enumerate(accuracies) if acc >= 95]\n",
    "best_classes.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"\\nðŸŒŸ Best Performing Letters (â‰¥95% accuracy):\")\n",
    "for letter, acc in best_classes[:5]:\n",
    "    print(f\"   {letter}: {acc:.2f}%\")\n",
    "\n",
    "# Worst performing classes\n",
    "worst_classes = [(categories[i], acc) for i, acc in enumerate(accuracies) if acc < 50]\n",
    "worst_classes.sort(key=lambda x: x[1])\n",
    "\n",
    "print(f\"\\nâš ï¸  Letters Needing Improvement (<50% accuracy):\")\n",
    "for letter, acc in worst_classes:\n",
    "    print(f\"   {letter}: {acc:.2f}%\")\n",
    "\n",
    "print(f\"\\nðŸ“Š All visualizations saved to: {OUTPUT_DIR}/\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… VISUALIZATION COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec64c277",
   "metadata": {},
   "source": [
    "## 18. List All Generated Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b8c718",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ“ Generated Visualization Files:\\n\")\n",
    "\n",
    "files = sorted(os.listdir(OUTPUT_DIR))\n",
    "for i, file in enumerate(files, 1):\n",
    "    file_path = os.path.join(OUTPUT_DIR, file)\n",
    "    file_size = os.path.getsize(file_path) / 1024  # KB\n",
    "    print(f\"  {i:2d}. {file:40s} ({file_size:6.1f} KB)\")\n",
    "\n",
    "print(f\"\\nâœ… Total files created: {len(files)}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
